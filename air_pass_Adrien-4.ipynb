{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science</a>\n",
    "# <a href=https://ramp.r0h.eu/problems/air_passengers>RAMP</a> on predicting the number of air passengers\n",
    "\n",
    "<i> Balázs Kégl (LAL/CNRS), Alex Gramfort (LTCI/Telecom ParisTech), Djalel Benbouzid (UPMC), Mehdi Cherti (LAL/CNRS) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The data set was donated to us by an unnamed company handling flight ticket reservations. The data is thin, it contains\n",
    "<ul>\n",
    "<li> the date of departure\n",
    "<li> the departure airport\n",
    "<li> the arrival airport\n",
    "<li> the mean and standard deviation of the number of weeks of the reservations made before the departure date\n",
    "<li> a field called <code>log_PAX</code> which is related to the number of passengers (the actual number were changed for privacy reasons)\n",
    "</ul>\n",
    "\n",
    "The goal is to predict the <code>log_PAX</code> column. The prediction quality is measured by RMSE. \n",
    "\n",
    "The data is obviously limited, but since data and location informations are available, it can be joined to external data sets. <b>The challenge in this RAMP is to find good data that can be correlated to flight traffic</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do :\n",
    "- mean encoding \n",
    "- regrouper variables catégoriques\n",
    "- ajouter nouvelles données : distance aéroports (trouver fichier avec données)\n",
    "- faire analyses descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data and load it in pandas\n",
    "\n",
    "First we load `problem.py` that parameterizes the challenge. It contains some objects taken off the shelf from `ramp-workflow` (e.g., `Predictions` type, scores, and data reader). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = imp.load_source('', 'problem.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_train_data` loads the training data and returns an `pandas` object (input) and a `np.array` object (output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_array = problem.get_train_data()\n",
    "# the y array contains the log-like number of passengers on each flight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-09-01\n",
      "2013-03-05\n"
     ]
    }
   ],
   "source": [
    "print(min(X_df['DateOfDeparture']))\n",
    "print(max(X_df['DateOfDeparture']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WeeksToDeparture   std_wtd    log_PAX DateOfDeparture Departure Arrival\n",
       "0         12.875000  9.812647  12.331296      2012-06-19       ORD     DFW\n",
       "1         14.285714  9.466734  10.775182      2012-09-10       LAS     DEN\n",
       "2         10.863636  9.035883  11.083177      2012-10-05       DEN     LAX\n",
       "3         11.480000  7.990202  11.169268      2011-10-09       ATL     ORD\n",
       "4         11.450000  9.517159  11.269364      2012-02-21       DEN     SFO"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df['log_PAX'] = y_array\n",
    "cols = X_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "X_df = X_df[cols]\n",
    "X_encoded = X_df\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('submissions/starting_kit/external_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_encoded = X_df\n",
    "external_data = data[['DateOfDeparture', 'Departure','Arrival', 'Mean TemperatureC', 'Distance',\n",
    "                      'MeanDew PointC', 'Mean Humidity', 'Min VisibilitykM', 'Mean Sea Level PressurehPa',\n",
    "                      'Max Wind SpeedKm/h', 'Precipitationmm', 'CloudCover',\n",
    "                      'Events','dep_encod','ar_encod','Number_hab','Revenue']]\n",
    "X_encoded = pd.merge(\n",
    "            X_encoded, external_data, how='left',\n",
    "            left_on=['DateOfDeparture', 'Arrival','Departure'],\n",
    "            right_on=['DateOfDeparture', 'Arrival','Departure'],\n",
    "            sort=False)\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.drop(['std_wtd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Departure'], prefix='d'))\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['Arrival'], prefix='a'))\n",
    "X_encoded = X_encoded.drop('Departure', axis=1)\n",
    "X_encoded = X_encoded.drop('Arrival', axis=1)\n",
    "\n",
    "X_encoded['DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "\n",
    "X_encoded['year']    = X_encoded['DateOfDeparture'].dt.year\n",
    "X_encoded['month']   = X_encoded['DateOfDeparture'].dt.month\n",
    "X_encoded['day']     = X_encoded['DateOfDeparture'].dt.day\n",
    "X_encoded['weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "X_encoded['week']    = X_encoded['DateOfDeparture'].dt.week\n",
    "X_encoded['n_days']  = X_encoded['DateOfDeparture'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)\n",
    "\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['year'], prefix='y'))\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['month'], prefix='m'))\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['day'], prefix='d'))\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['weekday'], prefix='wd'))\n",
    "X_encoded = X_encoded.join(pd.get_dummies(X_encoded['week'], prefix='w'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['day', 'log_PAX']].groupby(['day']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['year', 'log_PAX']].groupby(['year']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['month', 'log_PAX']].groupby(['month']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_encoded[['week', 'log_PAX']].groupby(['week']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['weekday', 'log_PAX']].groupby(['weekday']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.drop(['year', 'month', 'day', 'weekday', 'week', 'n_days','DateOfDeparture'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded['Events'].fillna(0, inplace=True)\n",
    "X_encoded['Events'] = X_encoded['Events'].replace(['Rain','Fog'], 1)\n",
    "X_encoded['Events'] = X_encoded['Events'].replace(['Rain-Thunderstorm','Fog-Rain-Thunderstorm', \n",
    "                                                         'Rain-Snow','Snow','Fog-Rain','Thunderstorm','Fog-Snow', \n",
    "                                                         'Fog-Rain-Snow','Fog-Rain-Snow-Thunderstorm', \n",
    "                                                         'Rain-Snow-Thunderstorm','Rain-Hail-Thunderstorm', \n",
    "                                                         'Fog-Rain-Hail-Thunderstorm', \n",
    "                                                         'Rain-Thunderstorm-Tornado'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded['Precipitationmm'] = X_encoded['Precipitationmm'].replace('T', np.nan)\n",
    "X_encoded['Precipitationmm'] = pd.to_numeric(X_encoded['Precipitationmm'])\n",
    "X_encoded['Precipitationmm'] = X_encoded['Precipitationmm'].fillna(X_encoded['Precipitationmm'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded['Precipitationmm*CloudCover'] = X_encoded.Precipitationmm * X_encoded.CloudCover\n",
    "X_encoded['Temperature*Humidity'] = X_encoded['Mean TemperatureC'] * X_encoded['Mean Humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded['Weeks_to_dep_int'] = pd.qcut(X_encoded['WeeksToDeparture'], 4)\n",
    "X_encoded.loc[X_encoded['WeeksToDeparture'] <= 9.524, 'WeeksToDeparture'] = 0\n",
    "X_encoded.loc[(X_encoded['WeeksToDeparture'] > 9.524) & (X_encoded['WeeksToDeparture'] <= 11.3), 'WeeksToDeparture'] = 1\n",
    "X_encoded.loc[(X_encoded['WeeksToDeparture'] > 11.3) & (X_encoded['WeeksToDeparture'] <= 13.24), 'WeeksToDeparture'] = 2\n",
    "X_encoded.loc[ X_encoded['WeeksToDeparture'] > 13.24, 'WeeksToDeparture'] = 3\n",
    "X_encoded['WeeksToDeparture'] = X_encoded['WeeksToDeparture'].astype(int)\n",
    "X_encoded.drop(['Weeks_to_dep_int'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_PAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.213970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.010436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.934104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.838703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    log_PAX\n",
       "WeeksToDeparture           \n",
       "3                 11.213970\n",
       "2                 11.010436\n",
       "1                 10.934104\n",
       "0                 10.838703"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded[['WeeksToDeparture', 'log_PAX']].groupby(['WeeksToDeparture']).mean().sort_values(by='log_PAX', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.loc[:, 'Precipitationmm*CloudCover' : 'Temperature*Humidity'] = StandardScaler().fit_transform(\n",
    "                                                            X_encoded.loc[:, 'Precipitationmm*CloudCover' : 'Temperature*Humidity'])\n",
    "\n",
    "X_encoded.loc[:, 'Distance' : 'Max Wind SpeedKm/h'] = StandardScaler().fit_transform(\n",
    "                                                            X_encoded.loc[:, 'Distance' : 'Max Wind SpeedKm/h'])\n",
    "\n",
    "X_encoded.loc[:, 'dep_encod' : 'Revenue'] = StandardScaler().fit_transform(\n",
    "                                                            X_encoded.loc[:, 'dep_encod' : 'Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_encoded.drop(['Mean TemperatureC','Mean Humidity','Precipitationmm','CloudCover'], axis=1, inplace=True)\n",
    "X_encoded.drop(['MeanDew PointC', 'Mean Sea Level PressurehPa'], axis=1, inplace=True)\n",
    "X_encoded.drop(['ar_encod'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_encoded['log_PAX']\n",
    "X_encoded.drop(['log_PAX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "data_dmatrix = xgb.DMatrix(data=X_encoded,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch\n",
    "import xgboost as xgb\n",
    "xgb1 = xgb.XGBRegressor()\n",
    "parameters = {'nthread':[4],\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.2], \n",
    "              'max_depth': [7],\n",
    "              'min_child_weight': [4],\n",
    "              'subsample': [0.95],\n",
    "              'colsample_bytree': [0.55],\n",
    "              'n_estimators': [100,300,500,1000],\n",
    "              'reg_lambda':[0.001],\n",
    "              'gamma':[0]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train, Y_train)\n",
    "\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'nthread':4,\n",
    "              'objective':'reg:squarederror',\n",
    "              'learning_rate': .3, \n",
    "              'max_depth': 7,\n",
    "              'min_child_weight': 4,\n",
    "              'subsample': 0.95,\n",
    "              'colsample_bytree': 0.55,\n",
    "              'n_estimators': 1000,\n",
    "              'reg_lambda':0.001,\n",
    "              'gamma':0}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=parameters, nfold=3,\n",
    "                    num_boost_round=300,early_stopping_rounds=5,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((cv_results[\"train-rmse-mean\"]).tail(1))\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.train(params=parameters, dtrain=data_dmatrix, num_boost_round=10)\n",
    "xgb.plot_importance(xg_reg, max_num_features=40)\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lightgbm = LGBMRegressor(task= 'train',\n",
    "          boosting_type= 'gbdt',\n",
    "          objective= 'regression',\n",
    "          metric= {'l2','auc'},\n",
    "          num_leaves= 300,\n",
    "          learning_rate= 0.32,\n",
    "          feature_fraction= 0.9,\n",
    "          bagging_fraction= .9,\n",
    "          bagging_freq= 70,\n",
    "          verbose= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = lgb.cv(dtrain=data_dmatrix, params=parameters, nfold=3,\n",
    "                    num_boost_round=300,early_stopping_rounds=5,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
